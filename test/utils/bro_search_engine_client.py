"""
This module is used to interact with Search Engine

The client communicates with Search Engine without using a secured TLS
connection therefore a cleartext REST interface is enabled in Search engine
by setting 'eric-data-search-engine.service.endpoints.rest.tls.enforced' to
'optional' in the values.yaml file.
"""
from opensearchpy import OpenSearch
from utilprocs import log


class SearchEngineClient:
    """
    This class is used to connect to Search Engine, retrieve logs from it,
    and format the logs.
    """

    def __init__(self):
        """
        This is the constructor of the class.
        """

        self.host = 'eric-data-search-engine'
        self.port = 9200
        self.client = OpenSearch(
            hosts=[{'host': self.host, 'port': self.port}],
            use_ssl=False,
            verify_certs=False,
            ssl_assert_hostname=False,
            ssl_show_warn=False
        )

    def retrieve_logs_from_service(self, service_name, output_size=10000):
        """
        Retrieves a given number of logs from a specified service in the
        deployment.

        :param service_name: name of the service from which you want to
        retrieve the logs.
        :param output_size: number of logs you want to retrieve from given
        service (max 10,000 - if more is required use scroll method). These
        are the first logs in Search Engine not the latest.
        :return: output from Search Engine in the format of a python
        dictionary.
        """

        day = 0  # Index to the first day that Search Engine is deployed
        index = self.client.cat.indices().split("\n")[day].split(" ")[2]
        log("Retrieved indices: {}".format(self.client.cat.indices()))

        """
        'index' is the index you want to search (eg "adp-app-logs-2023.02.23")
        'body' is a JSON-formatted string that represents the search request
        which is used to specify which service we want the logs from.
        This method returns its output in the form of a dictionary.
        """
        retrieved_logs_dict = self.client.search(
            index=index,
            sort="timestamp:asc",
            size=output_size,
            body={"query": {"match": {"service_id": service_name}}}
        )

        return retrieved_logs_dict

    def retrieve_logs_from_service_scroll(self, service_name):
        """
        Retrieves all the logs generated by a specified service from its
        initial deployment day.

        :param service_name: name of the service from which you want to
        retrieve the logs.
        :return: output from Search Engine in the format of a python
        dictionary.
        """

        day = 0  # Index to the first day that Search Engine is deployed
        index = self.client.cat.indices().split("\n")[day].split(" ")[2]

        """
        Initialise the "scroll" by searching for logs.
        '2m' is the period of time the search context is kept. This is the
        amount of time OpenSearch has to process the search results.
        'size' is the number of results you want returned from a batch of
        logs.
        OpenSearch caches the results and returns a scroll ID to access the
        results in batches. scroll ID is a pointer to where the previous search
        ended and where the next search will continue from.
        This scroll ID is passed to the 'scroll' opeartion to get back the
        next 10,000 logs, as long as the search context is still open.
        """
        data = self.client.search(
            index=index,
            sort="timestamp:asc",
            scroll='2m',
            size=10000,
            body={"query": {"match": {"service_id": service_name}}}
        )

        sid = data['_scroll_id']  # Get the scroll ID
        # Check if there are more logs to search
        scroll_size = len(data['hits']['hits'])

        retrieved_logs_dict = {}
        retrieved_logs_dict.update(data)  # Add retrieved data

        # While there is more to scroll, continue scrolling
        while scroll_size > 0:
            # Scroll to retrieve next 10,000/remaining logs
            data = self.client.scroll(scroll_id=sid, scroll='2m')

            # Append the data from the scroll to the list of "hits" inside
            # the dictionary.
            retrieved_logs_dict["hits"]["hits"].extend(data["hits"]["hits"])

            sid = data['_scroll_id']  # Update the scroll ID

            # Get the number of results that returned in the last scroll
            scroll_size = len(data['hits']['hits'])

        # Close the search context because the 'scroll' operation continues
        # to consume computing resources until the timeout.
        self.client.clear_scroll(scroll_id=sid)

        return retrieved_logs_dict

    # This method is not being used.
    # Decision made to keep this for now to be used as a basis for schema
    # verification test in early Q2.
    @classmethod
    def format_schema_into_log_message(cls, log_dictionary):
        """
        Formats raw output from Search Engine into neat log messages that
        include a timestamp of when the log was taken, the severity of the
        log, and the log message.
        """

        # For each entry in the list, take the timestamp, severity, and log
        # message, and save it.
        log_messages = [(x["_source"]["timestamp"] + " : " +
                         x["_source"]["severity"] + " : " +
                         x["_source"]["message"])
                        for x in log_dictionary["hits"]["hits"]]

        return log_messages
